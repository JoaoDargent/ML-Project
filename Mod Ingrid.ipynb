{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import zipfile, io\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Statistical libraries\n",
    "import scipy.stats as ss\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Scikit-learn preprocessing and model selection\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Scikit-learn feature selection\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, mutual_info_classif, RFE, RFECV\n",
    "\n",
    "# Scikit-learn models\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Scikit-learn metrics\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Pickle for import and export of datasets\n",
    "import pickle\n",
    "\n",
    "# Seaborn settings\n",
    "sns.set()\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable inline plotting for Jupyter notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('datasets/final_data_train_delivery1.csv', index_col=0)\n",
    "y_train = pd.read_csv('datasets/scaled_target_train_delivery1.csv', index_col=0)\n",
    "X_test = pd.read_csv('datasets/final_data_test_delivery1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE FOR NUNO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I am making predictions for both X_train and X_val ##\n",
    "\n",
    "Predictions on X_train:\n",
    "Why?\n",
    "To evaluate how well the model has learned the training data. This can help detect:\n",
    "\n",
    "Underfitting: If the training accuracy or F1 score is low, the model may not be complex enough to learn the patterns in the data.\n",
    "\n",
    "Overfitting: If the training accuracy is much higher than the validation accuracy, the model may have memorized the training data rather than generalizing.\n",
    "\n",
    "Predictions on X_val:\n",
    "Why?\n",
    "\n",
    "To evaluate how well the model generalizes to unseen data (validation set). This is the primary metric for model performance and gives an indication of how the model will perform on real-world data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE FOR NUNO: TO MAKE SURE IT RUNS;\n",
    "#Ensure that y_train and y_val are encoded as numeric labels\n",
    "#Ensure X_train, X_val, y_train, and y_val are defined and properly preprocessed.\n",
    "#Need to be scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "logistic_model = LogisticRegression()\n",
    "# Fit the model on the training data\n",
    "logistic_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training set\n",
    "train_pred = logistic_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_pred = logistic_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance on the training data (optional, for overfitting detection)\n",
    "print(\"Training Data Evaluation:\")\n",
    "print(f\"Accuracy (Train): {accuracy_score(y_train, train_pred)}\")\n",
    "print(f\"F1 Score (Train): {f1_score(y_train, train_pred, average='weighted')}\")\n",
    "\n",
    "# Evaluate performance on the validation data\n",
    "print(\"\\nValidation Data Evaluation:\")\n",
    "print(f\"Accuracy (Validation): {accuracy_score(y_val, val_pred)}\")\n",
    "print(f\"F1 Score (Validation): {f1_score(y_val, val_pred, average='weighted')}\")\n",
    "\n",
    "# Generate classification report for validation\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_val, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate  the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, val_pred)\n",
    "\n",
    "# Convert the confusion matrix into a DataFrame\n",
    "conf_matrix_df = pd.DataFrame(\n",
    "    conf_matrix, \n",
    "    index=[f\"Actual_{label}\" for label in logistic_model.classes_], \n",
    "    columns=[f\"Predicted_{label}\" for label in logistic_model.classes_]\n",
    ")\n",
    "print(\"\\nConfusion Matrix as DataFrame:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=logistic_model.classes_, yticklabels=logistic_model.classes_)\n",
    "plt.title(\"Confusion Matrix (Validation)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD HERE THE SCORE FROM KAGGLE= "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tenho 1 meu, tenho de correr primeiro e depois checkar este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Requirements for this to run\n",
    "X_train, y_train: Training feature set and target labels.\n",
    "X_val, y_val: Validation feature set and target labels.\n",
    "\n",
    "Define n_estimators_range with reasonable values.Larger values of n_estimators will increase model complexity and runtime.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the function to find the best number of trees (from the earlier example)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_best_n_estimators(X_train, y_train, X_val, y_val, n_estimators_range):\n",
    "    results = []\n",
    "\n",
    "    for n in n_estimators_range:\n",
    "        rf_model = RandomForestClassifier(n_estimators=n, random_state=42, class_weight='balanced')\n",
    "        rf_model.fit(X_train, y_train)\n",
    "        val_pred = rf_model.predict(X_val)\n",
    "        f1 = f1_score(y_val, val_pred, average='weighted')\n",
    "        results.append({'n_estimators': n, 'F1 Score': f1})\n",
    "        print(f\"n_estimators: {n}, F1 Score: {f1}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    best_n_estimators = results_df.loc[results_df['F1 Score'].idxmax(), 'n_estimators']\n",
    "    print(f\"\\nBest n_estimators: {best_n_estimators} with F1 Score: {results_df['F1 Score'].max()}\")\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(results_df['n_estimators'], results_df['F1 Score'], marker='o')\n",
    "    plt.title('F1 Score vs. Number of Trees (n_estimators)')\n",
    "    plt.xlabel('Number of Trees (n_estimators)')\n",
    "    plt.ylabel('F1 Score')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return best_n_estimators, results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the range of n_estimators\n",
    "n_estimators_range = range(10, 201, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Find the best number of trees\n",
    "best_n, results_df = find_best_n_estimators(X_train, y_train, X_val, y_val, n_estimators_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Train the final Random Forest model with the best number of trees\n",
    "random_forest_model = RandomForestClassifier(\n",
    "    n_estimators=best_n, \n",
    "    random_state=42, \n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "random_forest_model.fit(X_train, y_train)\n",
    "\n",
    "# Step 4: Make predictions and evaluate the final model\n",
    "train_pred = random_forest_model.predict(X_train)\n",
    "val_pred = random_forest_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTraining Data Evaluation:\")\n",
    "print(f\"Accuracy (Train): {accuracy_score(y_train, train_pred)}\")\n",
    "print(f\"F1 Score (Train): {f1_score(y_train, train_pred, average='weighted')}\")\n",
    "\n",
    "print(\"\\nValidation Data Evaluation:\")\n",
    "print(f\"Accuracy (Validation): {accuracy_score(y_val, val_pred)}\")\n",
    "print(f\"F1 Score (Validation): {f1_score(y_val, val_pred, average='weighted')}\")\n",
    "\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_val, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_val, val_pred)\n",
    "conf_matrix_df = pd.DataFrame(\n",
    "    conf_matrix,\n",
    "    index=[f\"Actual_{label}\" for label in random_forest_model.classes_],\n",
    "    columns=[f\"Predicted_{label}\" for label in random_forest_model.classes_]\n",
    ")\n",
    "\n",
    "print(\"\\nConfusion Matrix as DataFrame:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=random_forest_model.classes_, yticklabels=random_forest_model.classes_)\n",
    "plt.title(\"Confusion Matrix (Validation)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD HERE THE SCORE FROM KAGGLE= "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tenho 1 meu, tenho de correr primeiro e depois checkar este"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (2584167092.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[16], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    '''Requirements for this to run\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "'''Requirements for this to run\n",
    "Training and Validation Data:\n",
    "X_train, y_train: Training features and target labels.\n",
    "X_val, y_val: Validation features and target labels.\n",
    "Preprocessing:\n",
    "Feature data (X_train, X_val) must be numeric.\n",
    "Target labels (y_train, y_val) should be categorical or binary for classification tasks.\n",
    "Handle missing values, encoding, and scaling before using the data.\n",
    "\n",
    "Parameter Grid:\n",
    "\n",
    "You need to specify a parameter grid to explore combinations of:\n",
    "n_estimators: Number of boosting stages.\n",
    "learning_rate: Controls the contribution of each tree.\n",
    "max_depth: Depth of the trees.\n",
    "subsample: Proportion of samples used for training each base learner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the model\n",
    "gb_model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],         # Number of boosting stages\n",
    "    'learning_rate': [0.01, 0.1, 0.2],     # Learning rate\n",
    "    'max_depth': [3, 5, 7],                # Maximum depth of the individual estimators\n",
    "    'subsample': [0.8, 1.0],               # Fraction of samples for fitting base learners\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=gb_model, \n",
    "    param_grid=param_grid, \n",
    "    scoring='f1_weighted',  # Use F1-weighted score as the metric\n",
    "    cv=3,                   # 3-fold cross-validation\n",
    "    verbose=2,              # Verbosity for updates\n",
    "    n_jobs=-1               # Use all processors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit GridSearchCV on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve the best parameters and model\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "print(\"\\nBest Parameters:\")\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the best model\n",
    "train_pred = best_model.predict(X_train)\n",
    "val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Evaluate performance on the training data\n",
    "print(\"Training Data Evaluation:\")\n",
    "print(f\"Accuracy (Train): {accuracy_score(y_train, train_pred)}\")\n",
    "print(f\"F1 Score (Train): {f1_score(y_train, train_pred, average='weighted')}\")\n",
    "\n",
    "# Evaluate performance on the validation data\n",
    "print(\"\\nValidation Data Evaluation:\")\n",
    "print(f\"Accuracy (Validation): {accuracy_score(y_val, val_pred)}\")\n",
    "print(f\"F1 Score (Validation): {f1_score(y_val, val_pred, average='weighted')}\")\n",
    "\n",
    "# Generate classification report for validation data\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_val, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix for validation data\n",
    "conf_matrix = confusion_matrix(y_val, val_pred)\n",
    "\n",
    "# Convert confusion matrix to a DataFrame\n",
    "conf_matrix_df = pd.DataFrame(\n",
    "    conf_matrix,\n",
    "    index=[f\"Actual_{label}\" for label in best_model.classes_],\n",
    "    columns=[f\"Predicted_{label}\" for label in best_model.classes_]\n",
    ")\n",
    "\n",
    "# Display the confusion matrix as a DataFrame\n",
    "print(\"\\nConfusion Matrix as DataFrame:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=best_model.classes_, yticklabels=best_model.classes_)\n",
    "plt.title(\"Confusion Matrix (Validation)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADD HERE THE SCORE FROM KAGGLE= "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "model_complex = MLPClassifier(hidden_layer_sizes=(100,100,100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MLPClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.neural_network.MLPClassifier.html\">?<span>Documentation for MLPClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100))</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 100, 100, 100))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''model_complex.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''predictNN = model_complex.predict(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naives Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements\n",
    "2. Input Data\n",
    "Training and Validation Data:\n",
    "X_train, y_train: Training features and target labels.\n",
    "X_val, y_val: Validation features and target labels.\n",
    "Preprocessing:\n",
    "Numeric Data:\n",
    "GaussianNB assumes numeric feature values. Ensure all features in X_train and X_val are numeric.\n",
    "Categorical Labels:\n",
    "The target labels (y_train, y_val) should be categorical or binary for classification tasks.\n",
    "No Missing Values:\n",
    "Handle missing values before fitting the model.\n",
    "\n",
    "3. GaussianNB Specific Requirements\n",
    "Feature Distribution:\n",
    "GaussianNB assumes that features follow a normal (Gaussian) distribution. While not strictly enforced, this assumption impacts performance.\n",
    "Variance Smoothing:\n",
    "The parameter var_smoothing=1e-9 prevents division by zero by adding a small value to variances. Adjust if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the Gaussian Naive Bayes model with variance smoothing\n",
    "gnb_model = GaussianNB(var_smoothing=1e-9)\n",
    "\n",
    "# Fit the model on the training data\n",
    "gnb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training set\n",
    "train_pred = gnb_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_pred = gnb_model.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance on the training data\n",
    "print(\"Training Data Evaluation:\")\n",
    "print(f\"Accuracy (Train): {accuracy_score(y_train, train_pred)}\")\n",
    "print(f\"F1 Score (Train): {f1_score(y_train, train_pred, average='weighted')}\")\n",
    "\n",
    "# Evaluate performance on the validation data\n",
    "print(\"\\nValidation Data Evaluation:\")\n",
    "print(f\"Accuracy (Validation): {accuracy_score(y_val, val_pred)}\")\n",
    "print(f\"F1 Score (Validation): {f1_score(y_val, val_pred, average='weighted')}\")\n",
    "\n",
    "# Generate classification report for validation\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_val, val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and visualize the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_val, val_pred)\n",
    "\n",
    "# Convert the confusion matrix into a DataFrame\n",
    "conf_matrix_df = pd.DataFrame(\n",
    "    conf_matrix, \n",
    "    index=[f\"Actual_{label}\" for label in gnb_model.classes_], \n",
    "    columns=[f\"Predicted_{label}\" for label in gnb_model.classes_]\n",
    ")\n",
    "\n",
    "# Display the confusion matrix as a DataFrame\n",
    "print(\"\\nConfusion Matrix as DataFrame:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=gnb_model.classes_, yticklabels=gnb_model.classes_)\n",
    "plt.title(\"Confusion Matrix (Validation)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import pandas as pd\n",
    "\n",
    "def find_best_k(X_train, y_train, X_val, y_val, ks):\n",
    "    results = []  # Correct indentation for results initialization\n",
    "\n",
    "    for k in ks:\n",
    "        # Initialize the KNN model with the current k\n",
    "        knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "        # Fit the model to the training data\n",
    "        knn_model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict on the validation set\n",
    "        val_pred = knn_model.predict(X_val)\n",
    "\n",
    "        # Calculate the F1 Macro score\n",
    "        f1_macro = f1_score(y_val, val_pred, average='macro')\n",
    "        results.append({'k': k, 'F1 Macro': f1_macro})\n",
    "\n",
    "        # Print results for each k\n",
    "        print(f\"k: {k}, F1 Macro: {f1_macro}\")\n",
    "\n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    # Find the best k\n",
    "    best_k = results_df.loc[results_df['F1 Macro'].idxmax(), 'k']\n",
    "    print(f\"\\nBest k: {best_k} with F1 Macro: {results_df['F1 Macro'].max()}\")\n",
    "\n",
    "    # Plot the F1 Macro scores\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(results_df['k'], results_df['F1 Macro'], marker='o')\n",
    "    plt.title('F1 Macro vs. Number of Neighbors (k)')\n",
    "    plt.xlabel('Number of Neighbors (k)')\n",
    "    plt.ylabel('F1 Macro Score')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "    return best_k, results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_k = 5  # Example\n",
    "\n",
    "# Initialize the KNN model with the best k\n",
    "knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "# Fit the model on the training data\n",
    "knn_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the training set\n",
    "train_pred = knn_model.predict(X_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_pred = knn_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate performance on the training data\n",
    "print(\"Training Data Evaluation:\")\n",
    "print(f\"Accuracy (Train): {accuracy_score(y_train, train_pred)}\")\n",
    "print(f\"F1 Score (Train): {f1_score(y_train, train_pred, average='weighted')}\")\n",
    "\n",
    "# Evaluate performance on the validation data\n",
    "print(\"\\nValidation Data Evaluation:\")\n",
    "print(f\"Accuracy (Validation): {accuracy_score(y_val, val_pred)}\")\n",
    "print(f\"F1 Score (Validation): {f1_score(y_val, val_pred, average='weighted')}\")\n",
    "\n",
    "# Generate classification report for validation data\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_val, val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix for validation data\n",
    "conf_matrix = confusion_matrix(y_val, val_pred)\n",
    "\n",
    "# Convert confusion matrix to a DataFrame\n",
    "conf_matrix_df = pd.DataFrame(\n",
    "    conf_matrix,\n",
    "    index=[f\"Actual_{label}\" for label in knn_model.classes_],\n",
    "    columns=[f\"Predicted_{label}\" for label in knn_model.classes_]\n",
    ")\n",
    "\n",
    "# Display the confusion matrix as a DataFrame\n",
    "print(\"\\nConfusion Matrix as DataFrame:\")\n",
    "print(conf_matrix_df)\n",
    "\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=knn_model.classes_, yticklabels=knn_model.classes_)\n",
    "plt.title(\"Confusion Matrix (Validation)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded Mehtods ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Voting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize the individual models\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "random_forest_model = RandomForestClassifier(random_state=42, n_estimators=100, class_weight='balanced')\n",
    "gradient_boosting_model = GradientBoostingClassifier(random_state=42, n_estimators=100)\n",
    "\n",
    "# Combine models in a VotingClassifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('lr', logistic_model),\n",
    "        ('rf', random_forest_model),\n",
    "        ('gb', gradient_boosting_model)\n",
    "    ],\n",
    "    voting='soft'  # Soft voting for probability-based aggregation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the ensemble model\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the training set\n",
    "train_pred = voting_clf.predict(X_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "val_pred = voting_clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the ensemble on the training set\n",
    "print(\"Training Data Evaluation:\")\n",
    "print(f\"Accuracy (Train): {accuracy_score(y_train, train_pred):.4f}\")\n",
    "print(f\"F1 Score (Train): {f1_score(y_train, train_pred, average='weighted'):.4f}\")\n",
    "\n",
    "# Evaluate the ensemble on the validation set\n",
    "print(\"\\nValidation Data Evaluation:\")\n",
    "print(f\"Accuracy (Validation): {accuracy_score(y_val, val_pred):.4f}\")\n",
    "print(f\"F1 Score (Validation): {f1_score(y_val, val_pred, average='weighted'):.4f}\")\n",
    "\n",
    "# Generate classification report for validation data\n",
    "print(\"\\nClassification Report (Validation):\")\n",
    "print(classification_report(y_val, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix for validation data\n",
    "conf_matrix = confusion_matrix(y_val, val_pred)\n",
    "\n",
    "# Visualize the confusion matrix as a heatmap\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", \n",
    "            xticklabels=voting_clf.classes_, yticklabels=voting_clf.classes_)\n",
    "plt.title(\"Confusion Matrix - Voting Classifier\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Submissions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Reset index to include 'Claim Identifier' as a column if it's the index\n",
    "X_test = X_test.reset_index()\n",
    "\n",
    "label_mapping = {\n",
    "    0: \"1. CANCELLED\",\n",
    "    1: \"2. NON-COMP\",\n",
    "    2: \"3. MED ONLY\",\n",
    "    3: \"4. TEMPORARY\",\n",
    "    4: \"5. PPD SCH LOSS\",\n",
    "    5: \"6. PPD NSL\",\n",
    "    6: \"7. PTD\",\n",
    "    7: \"8. DEATH\",\n",
    "    8: \"Unknown\"\n",
    "}\n",
    "\n",
    "predictions = [label_mapping[label] for label in pred_RF]\n",
    "\n",
    "# Create the submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    'Claim Identifier': X_test['Claim Identifier'],  # Ensure this column exists\n",
    "    'Claim Injury Type': predictions                     # Replace 'pred_RF' with your predictions\n",
    "})\n",
    "\n",
    "# Save to CSV\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
