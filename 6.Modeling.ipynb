{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import zipfile, io\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "# Statistical libraries\n",
    "import scipy.stats as ss\n",
    "from scipy import stats\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Scikit-learn preprocessing and model selection\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Scikit-learn feature selection\n",
    "from sklearn.feature_selection import f_classif, SelectKBest, mutual_info_classif, RFE, RFECV\n",
    "\n",
    "# Scikit-learn models\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Scikit-learn metrics\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Pickle for import and export of datasets\n",
    "import pickle\n",
    "\n",
    "# Seaborn settings\n",
    "sns.set()\n",
    "\n",
    "# Ignore warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Enable inline plotting for Jupyter notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('datasets/final_data_train_delivery1.csv', index_col=0)\n",
    "y_train = pd.read_csv('datasets/scaled_target_train_delivery1.csv', index_col=0)\n",
    "X_test = pd.read_csv('datasets/final_data_test_delivery1.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the model\n",
    "#rf_model = RandomForestClassifier(class_weight=\"balanced\", random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nscorers = {\\n    \\'accuracy\\': \\'accuracy\\',\\n    \\'precision\\': make_scorer(precision_score, average=\\'weighted\\'),\\n    \\'recall\\': make_scorer(recall_score, average=\\'weighted\\'),\\n    \\'f1\\': make_scorer(f1_score, average=\\'weighted\\')\\n}\\n\\n# Perform cross-validation for each metric\\nfor metric_name, scorer in scorers.items():\\n    cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring=scorer)\\n    print(f\"Cross-validation {metric_name.capitalize()} for Random Forest: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "scorers = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score, average='weighted'),\n",
    "    'recall': make_scorer(recall_score, average='weighted'),\n",
    "    'f1': make_scorer(f1_score, average='weighted')\n",
    "}\n",
    "\n",
    "# Perform cross-validation for each metric\n",
    "for metric_name, scorer in scorers.items():\n",
    "    cv_scores = cross_val_score(rf_model, X_train, y_train, cv=5, scoring=scorer)\n",
    "    print(f\"Cross-validation {metric_name.capitalize()} for Random Forest: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictions for test set\n",
    "#pred_RF = rf_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient Boosting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the model\n",
    "#gb_model = GradientBoostingClassifier(random_state=42)\n",
    "#gb_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Perform cross-validation for each metric\\nfor metric_name, scorer in scorers.items():\\n    cv_scores = cross_val_score(gb_model, X_train, y_train, cv=5, scoring=scorer)\\n    print(f\"Cross-validation {metric_name.capitalize()} for Gradient Boosting: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Perform cross-validation for each metric\n",
    "for metric_name, scorer in scorers.items():\n",
    "    cv_scores = cross_val_score(gb_model, X_train, y_train, cv=5, scoring=scorer)\n",
    "    print(f\"Cross-validation {metric_name.capitalize()} for Gradient Boosting: {cv_scores.mean():.4f} ± {cv_scores.std():.4f}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_GB = gb_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "model_complex = MLPClassifier(hidden_layer_sizes=(100,100,100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_complex.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictNN = model_complex.predict(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Submissions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example mapping dictionary based on provided target categories\n",
    "label_mapping = {\n",
    "    0: \"1. CANCELLED\",\n",
    "    1: \"2. NON-COMP\",\n",
    "    2: \"3. MED ONLY\",\n",
    "    3: \"4. TEMPORARY\",\n",
    "    4: \"5. PPD SCH LOSS\",\n",
    "    5: \"6. PPD NSL\",\n",
    "    6: \"7. PTD\",\n",
    "    7: \"8. DEATH\",\n",
    "    8: \"Unknown\"\n",
    "}\n",
    "\n",
    "# Map numeric predictions to their string labels\n",
    "y_test_pred_mapped = [label_mapping[label] for label in pred_GB]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the submission DataFrame\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Claim Identifier\": X_test[\"Claim Identifier\"],  # Use the identifier column from df_test\n",
    "    \"Claim Injury Type\": y_test_pred_mapped\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to a CSV file for submission\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
